{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden Markov Models\n",
    "\n",
    "\n",
    "## Overview\n",
    "\n",
    "The goal is to demonstrate the power of probabalistic models. We will build a word recognizer for American Sign Language (ASL) video sequences. In particular, this project employs hidden Markov models (HMM's) to analyze a series of measurements taken from videos of American Sign Language (ASL) collected for research (see the [RWTH-BOSTON-104 Database](http://www-i6.informatik.rwth-aachen.de/~dreuw/database-rwth-boston-104.php)).\n",
    "\n",
    "In each video, an ASL signer is signing a meaningful sentence. In a typical ASL recognition system, you observe the XY coordinates of the speaker's left hand, right hand, and nose for every frame. The following diagram shows how the positions of the left hand (Red), right hand (Blue), and nose (Green) change over time in video number #66. Saturation of colors represents time elapsed.\n",
    "\n",
    "<img src=\"./demo/hands_nose_position.png\" alt=\"hands nose position\">\n",
    "\n",
    "This project will only use the Y-coordinates of each hand to construct the HMM. In Part 1 we will build a one dimensional model, recognizing words based only on a series of right-hand Y coordinates; in Part 2 we will go multidimensional and utilize both hands.\n",
    "\n",
    "The words will be recognizing are \"BUY\", \"HOUSE\", and \"CAR\". These individual signs can be seen in the sign phrases from the dataset:\n",
    "\n",
    "![](demo/buy_house_slow.gif) \n",
    "\n",
    "<p style=\"text-align:center; font-weight:bold\"> JOHN CAN BUY HOUSE </p> \n",
    "\n",
    "![](demo/buy_car_slow.gif) \n",
    "\n",
    "<p style=\"text-align:center;  font-weight:bold\"> JOHN BUY CAR [FUTURE] </p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the HMM\n",
    "\n",
    "Determine following values for each word:\n",
    "1. the transition probabilities of each state\n",
    "2. the mean & standard deviation of emission Gaussian distribution of each state\n",
    "\n",
    "\n",
    "\n",
    "#### When calculating the self transition probability (e.g. P(B2 -> B2)), calculate it as 1 - exit transition probability (e.g. 1 - P(B2->B3))\n",
    "\n",
    "Those values can be hardcoded in your program. Don't use round() from python.\n",
    "\n",
    "Word | Frames | Observed sequence | Initial State1 | Initial State2 | Initial State3\n",
    "--- | --- | --- | --- | --- | --- \n",
    "BUY | 6 | 36, 44, 52, 56, 49, 44 | 36, 44 | 52, 56 | 49, 44\n",
    "BUY | 8 | 42, 46, 54, 62, 68, 65, 60, 56 | 42, 46, 54 | 62, 68, 65 | 60, 56\n",
    "BUY | 10 | 42, 40, 41, 43, 52, 55, 59, 60, 55, 47 | 42, 40, 41|43, 52, 55|59, 60, 55, 47\n",
    "CAR | 10 | 47, 39, 32, 34, 36, 42, 42, 42, 34, 25|47, 39, 32|34, 36, 42|42, 42, 34, 25\n",
    "CAR | 9 | 35, 35, 43, 46, 52, 52, 56, 49, 45|35, 35, 43|46, 52, 52|56, 49, 45\n",
    "CAR | 8 | 28, 35, 46, 46, 48, 43, 43, 40|28, 35, 46|46, 48, 43|43, 40\n",
    "HOUSE| 15 | 37, 36, 32, 26, 26, 25, 23, 22, 21, 39, 48, 60, 70, 74, 77|37, 36, 32, 26, 26|25, 23, 22, 21, 39|48, 60, 70, 74, 77\n",
    "HOUSE| 15 | 50, 50, 49, 47, 39, 39, 38, 38, 50, 56, 61, 67, 67, 67, 67|50, 50, 49, 47, 39|39, 38, 38, 50, 56|61, 67, 67, 67, 67\n",
    "HOUSE| 16 | 45, 43, 44, 43, 40, 35, 36, 37, 39, 45, 60, 68, 66, 72, 72, 75|45, 43, 44, 43, 40|35, 36, 37, 39, 45|60, 68, 66, 72, 72, 75\n",
    "\n",
    "As shown in the diagram below, each one of the three words (BUY, CAR, and HOUSE) has exactly **THREE hidden states** in its HMM. All words have equal probability of occuring. Modify the prior accordingly. All words must start from State 1 and can only transit to the next state or stay in the current one as shown below:\n",
    "\n",
    "<img src=\"part_1_a_probs.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test on Linux/OS X system\n"
     ]
    }
   ],
   "source": [
    "import hmm_submission_test as tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HMM_encoder():\n",
    "\n",
    "    \"\"\"Word BUY\"\"\"\n",
    "    b_prior_probs = {\n",
    "        'B1': 0.333,\n",
    "        'B2': 0.000,\n",
    "        'B3': 0.000,\n",
    "        'Bend': 0.000,\n",
    "    }\n",
    "    b_transition_probs = {\n",
    "        'B1': {'B1': 0.625, 'B2': 0.375, 'B3': 0.000, 'Bend': 0.000},\n",
    "        'B2': {'B1': 0.000, 'B2': 0.625, 'B3': 0.375, 'Bend': 0.000},\n",
    "        'B3': {'B1': 0.000, 'B2': 0.000, 'B3': 0.625, 'Bend': 0.375},\n",
    "        'Bend': {'B1': 0.000, 'B2': 0.000, 'B3': 0.000, 'Bend': 1.000},\n",
    "    }\n",
    "    # Parameters for end state is not required\n",
    "    b_emission_paras = {\n",
    "        'B1': (41.750, 2.773),\n",
    "        'B2': (58.625, 5.678),\n",
    "        'B3': (53.125, 5.418),\n",
    "        'Bend': (None, None)\n",
    "    }\n",
    "\n",
    "    \"\"\"Word CAR\"\"\"\n",
    "    c_prior_probs = {\n",
    "        'C1': 0.333,\n",
    "        'C2': 0.000,\n",
    "        'C3': 0.000,\n",
    "        'Cend': 0.000,\n",
    "    }\n",
    "    c_transition_probs = {\n",
    "        'C1': {'C1': 0.667, 'C2': 0.333, 'C3': 0.000, 'Cend': 0.000},\n",
    "        'C2': {'C1': 0.000, 'C2': 0.000, 'C3': 1.000, 'Cend': 0.00},\n",
    "        'C3': {'C1': 0.000, 'C2': 0.000, 'C3': 0.800, 'Cend': 0.200},\n",
    "        'Cend': {'C1': 0.000, 'C2': 0.000, 'C3': 0.000, 'Cend': 1.000},\n",
    "    }\n",
    "    # Parameters for end state is not required\n",
    "    c_emission_paras = {\n",
    "        'C1': (35.667, 4.899),\n",
    "        'C2': (43.667, 1.700),\n",
    "        'C3': (44.200, 7.341),\n",
    "        'Cend': (None, None)\n",
    "    }\n",
    "\n",
    "    \"\"\"Word HOUSE\"\"\"\n",
    "    h_prior_probs = {\n",
    "        'H1': 0.333,\n",
    "        'H2': 0.000,\n",
    "        'H3': 0.000,\n",
    "        'Hend': 0.000,\n",
    "    }\n",
    "    # Probability of a state changing to another state.\n",
    "    h_transition_probs = {\n",
    "        'H1': {'H1': 0.667, 'H2': 0.333, 'H3': 0.000, 'Hend': 0.000},\n",
    "        'H2': {'H1': 0.000, 'H2': 0.857, 'H3': 0.143, 'Hend': 0.000},\n",
    "        'H3': {'H1': 0.000, 'H2': 0.000, 'H3': 0.812, 'Hend': 0.188},\n",
    "        'Hend': {'H1': 0.000, 'H2': 0.000, 'H3': 0.000, 'Hend': 1.000},\n",
    "    }\n",
    "    # Parameters for end state is not required\n",
    "    h_emission_paras = {\n",
    "        'H1': (45.333, 3.972),\n",
    "        'H2': (34.952, 8.127),\n",
    "        'H3': (67.438, 5.733),\n",
    "        'Hend': (None, None)\n",
    "    }\n",
    "\n",
    "    return (b_prior_probs, b_transition_probs, b_emission_paras,\n",
    "            c_prior_probs, c_transition_probs, c_emission_paras,\n",
    "            h_prior_probs, h_transition_probs, h_emission_paras,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Viterbi Trellis\n",
    "\n",
    "The goal here will be to use the HMM derived from above(states, prior probabilities, transition probabilities, and parameters of emission distribution) to build a viterbi trellis.  When provided with an evidence vector (list of observed right-hand Y coordinates), the function will return the most likely sequence of states that generated the evidence and the probabilty of that sequence being correct.\n",
    "\n",
    "For example, an evidence vector [36, 44, 52, 53, 49, 44] should output a sequence ['B1', ... 'B2', ... 'B3']\n",
    "\n",
    "If no sequence can be found, the algorithm should return one of the following tuples:\n",
    "`(None, 0)` (null),  `([], 0)` (empty list) or  `(['C1', 'C1', ... 'C1'],0)` (Or all being the first state of that letter)\n",
    "\n",
    "\"No sequence can be found\" means the probability reaches 0 midway. If you find an incomplete sequence with some probability, output that sequence with its probability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_prob(x, para_tuple):\n",
    "    \n",
    "    if list(para_tuple) == [None, None]:\n",
    "        return 0.0\n",
    "\n",
    "    mean, std = para_tuple\n",
    "    gaussian_percentile = (2 * np.pi * std**2)**-0.5 * \\\n",
    "                          np.exp(-(x - mean)**2 / (2 * std**2))\n",
    "    return gaussian_percentile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def viterbi(evidence_vector, states, prior_probs,\n",
    "            transition_probs, emission_paras):\n",
    "    sequence = []\n",
    "    probability = 0.0\n",
    "    \n",
    "    dict_1 = {}\n",
    "    dict_2 = {}\n",
    "    path = {}\n",
    "\n",
    "    if len(evidence_vector) == 0:\n",
    "        return sequence, probability\n",
    "\n",
    "    for state in states:\n",
    "        dict_1[state] = gaussian_prob(evidence_vector[0], emission_paras[state])\\\n",
    "                        * prior_probs[state]\n",
    "        path[state] = [state]\n",
    "        if dict_1[state] > probability:\n",
    "            probability = dict_1[state]\n",
    "            sequence = path[state] \n",
    "        \n",
    "    if len(evidence_vector)== 1:\n",
    "        return sequence, probability\n",
    "    \n",
    "    updated_path = {}        \n",
    "    for state in states:\n",
    "        #print('flag')\n",
    "        prob_ls = {}\n",
    "        for pre_state in (transition_probs[state].keys()):\n",
    "            probability = gaussian_prob(evidence_vector[1], emission_paras[state])\\\n",
    "                          * dict_1[pre_state] * transition_probs[pre_state][state]\n",
    "            prob_ls[probability] =  pre_state\n",
    "        probability = max(prob_ls)\n",
    "        dict_2[state] = probability\n",
    "        updated_path[state] = path[prob_ls[probability]] + [state]\n",
    "    path = updated_path\n",
    "\n",
    "\n",
    "    for i in range(len(evidence_vector)):\n",
    "        if i == 0 or i ==1:\n",
    "            continue\n",
    "        updated_path = {}\n",
    "        for state in states:\n",
    "            prob_ls = {}\n",
    "            for pre_state in (transition_probs[state].keys()):\n",
    "                probability = gaussian_prob(evidence_vector[i], emission_paras[state])\\\n",
    "                              * dict_2[pre_state] * transition_probs[pre_state][state]\n",
    "                prob_ls[probability] =  pre_state\n",
    "            probability = max(prob_ls)\n",
    "            dict_1[state] = probability\n",
    "            updated_path[state] = path[prob_ls[probability]] + [state]\n",
    "        path = updated_path\n",
    "        dict_2 = dict_1\n",
    "        dict_1 = {}\n",
    "        \n",
    "    probability = 0  \n",
    "    for state in dict_2:\n",
    "        if dict_2[state] > probability:\n",
    "            probability = dict_2[state]\n",
    "            sequence = path[state] \n",
    "\n",
    "    return sequence, probability\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multidimensional Output Probabilities\n",
    "\n",
    "We have used right-hand Y-axis coordinates as our sole feature in the above part, now we are going to use both hands. Since sign language is two-handed, using both hands as features can increase the accuracy of our model when dealing with more complex sentences.\n",
    "\n",
    "Here given with the transition probabilities, and the means & standard deviations for emission probabilties of left-hand Y-axis locations, following the same procedure conducted before.\n",
    "\n",
    "One thing to notice is, the `viterbi` function is tested against single words. In other words, the input evidence vector will not transit between different words. However, for this step, the input evidence vector can be either a single word, or a verb phrase such as \"BUY CAR\" and \"BUY HOUSE\". Adjust the probabilities in the image below to adapt to this fact. Note that consecutive words should be different.\n",
    "\n",
    "<img src=\"part_2_a_probs.png\" alt=\"2a_probs\">\n",
    "\n",
    "BUY | State 1 | State 2 | State 3\n",
    "--- | --- | --- | --- \n",
    "Mean | 108.200 | 78.670 | 64.182\n",
    "Std | 17.314 | 1.886 | 5.573\n",
    "\n",
    "CAR | State 1 | State 2 | State 3\n",
    "--- | --- | --- | --- \n",
    "Mean | 56.300 | 37.110 | 50.000\n",
    "Std | 10.659 | 4.306 | 7.826\n",
    "\n",
    "HOUSE | State 1 | State 2 | State 3\n",
    "--- | --- | --- | --- \n",
    "Mean | 53.600 | 37.168 | 74.176\n",
    "Std | 7.392 | 8.875 | 8.347\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_HMM():\n",
    "\n",
    "    b_prior_probs = {\n",
    "        'B1': 0.333,\n",
    "        'B2': 0.000,\n",
    "        'B3': 0.000,\n",
    "        'Bend': 0.000,\n",
    "    }\n",
    "    # example: {'B1': {'B1' : (right-hand Y, left-hand Y), ... }\n",
    "    b_transition_probs = {\n",
    "        'B1': {'B1': (0.625, 0.700), 'B2': (0.375, 0.300), 'B3': (0.000, 0.), 'Bend': (0.000, 0.000)},\n",
    "        'B2': {'B1': (0., 0.), 'B2': (0.625, 0.05), 'B3': (0.375, 0.95), 'Bend': (0.000, 0.000)},\n",
    "        'B3': {'B1': (0., 0.), 'B2': (0., 0.), 'B3': (0.625, 0.727), 'Bend': (0.125, 0.091), 'C1': (0.125, 0.091), 'H1': (0.125, 0.091)},\n",
    "        'Bend': {'B1': (0., 0.), 'B2': (0., 0.), 'B3': (0., 0.), 'Bend': (1., 1.)},\n",
    "    }\n",
    "    # example: {'B1': [(right-mean, right-std), (left-mean, left-std)] ...}\n",
    "    b_emission_paras = {\n",
    "        'B1': [(41.750, 2.773), (108.200, 17.314)],\n",
    "        'B2': [(58.625, 5.678), (78.670, 1.886)],\n",
    "        'B3': [(53.125, 5.418), (64.182, 5.573)],\n",
    "        'Bend': [(None, None), (None, None)]\n",
    "    }\n",
    "\n",
    "    \"\"\"Word Car\"\"\"\n",
    "    c_prior_probs = {\n",
    "        'C1': 0.333,\n",
    "        'C2': 0.000,\n",
    "        'C3': 0.000,\n",
    "        'Cend': 0.000,\n",
    "    }\n",
    "    c_transition_probs = {\n",
    "        'C1': {'C1': (0.667, 0.700), 'C2': (0.333, 0.300), 'C3': (0.000, 0.000), 'Cend': (0.000, 0.000)},\n",
    "        'C2': {'C1': (0.000, 0.000), 'C2': (0.000, 0.625), 'C3': (1.00, 0.375), 'Cend': (0.000, 0.000)},\n",
    "        'C3': {'C1': (0.000, 0.000), 'C2': (0.000, 0.000), 'C3': (0.800, 0.625), 'Cend': (0.067, 0.125), 'B1': (0.067, 0.125), 'H1': (0.067, 0.125)},\n",
    "        'Cend': {'C1': (0.000, 0.000), 'C2': (0.000, 0.000), 'C3': (0.000, 0.000), 'Cend': (1.000, 1.000)},\n",
    "    }\n",
    "    c_emission_paras = {\n",
    "        'C1': [(35.667, 4.899), (56.3, 10.659)],\n",
    "        'C2': [(43.667, 1.700), (37.11, 4.306)],\n",
    "        'C3': [(44.200, 7.341), (50.000, 7.826)],\n",
    "        'Cend': [(None, None), (None, None)]\n",
    "    }\n",
    "\n",
    "    \"\"\"Word HOUSE\"\"\"\n",
    "    h_prior_probs = {\n",
    "        'H1': 0.333,\n",
    "        'H2': 0.000,\n",
    "        'H3': 0.000,\n",
    "        'Hend': 0.000,\n",
    "    }\n",
    "    h_transition_probs = {\n",
    "        'H1': {'H1': (0.667, 0.7), 'H2': (0.333, 0.300), 'H3': (0.000, 0.000), 'Hend': (0.000, 0.000)},\n",
    "        'H2': {'H1': (0.000, 0.000), 'H2': (0.857, 0.842), 'H3': (0.143, 0.158), 'Hend': (0.000, 0.000)},\n",
    "        'H3': {'H1': (0.000, 0.000), 'H2': (0.000, 0.000), 'H3': (0.812, 0.824), 'Hend': ((0.063, 0.059)), 'B1': (0.063, 0.059), 'C1': (0.063, 0.059)},\n",
    "        'Hend': {'H1': (0.000, 0.000), 'H2': (0.000, 0.000), 'H3': (0.000, 0.000), 'Hend': (1.000, 1.000)},\n",
    "    }\n",
    "    h_emission_paras = {\n",
    "        'H1': [(45.333, 3.972), (53.600, 7.392)],\n",
    "        'H2': [(34.952, 8.127), (37.168, 8.875)],\n",
    "        'H3': [(67.438, 5.733), (74.176, 8.347)],\n",
    "        'Hend': [(None, None), (None, None)]\n",
    "    }\n",
    "\n",
    "    return (b_prior_probs, b_transition_probs, b_emission_paras,\n",
    "            c_prior_probs, c_transition_probs, c_emission_paras,\n",
    "            h_prior_probs, h_transition_probs, h_emission_paras,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improving the Viterbi Trellis\n",
    "\n",
    "Modify the Viterbi Trellis function to allow multiple observed values (Y location of right and left hands) for a state. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multidimensional_viterbi(evidence_vector, states, prior_probs,\n",
    "                             transition_probs, emission_paras):\n",
    " \n",
    "    sequence = []\n",
    "    probability = 0.0\n",
    "    \n",
    "    dict_1 = {}\n",
    "    dict_2 = {}\n",
    "    path = {}\n",
    "    updated_path = {}\n",
    "\n",
    "    if len(evidence_vector) == 0:\n",
    "        return sequence, probability\n",
    "\n",
    "    for state in states:\n",
    "        dict_1[state] = gaussian_prob(evidence_vector[0][0], emission_paras[state][0]) \\\n",
    "                 * gaussian_prob(evidence_vector[0][1], emission_paras[state][1]) \\\n",
    "                 * prior_probs[state]\n",
    "        path[state] = [state]\n",
    "        if dict_1[state] > probability:\n",
    "            probability = dict_1[state]\n",
    "            sequence = path[state]\n",
    "\n",
    "    if len(evidence_vector)== 1:\n",
    "        return sequence, probability\n",
    "    \n",
    "    for state in states:\n",
    "        prob_ls = {}\n",
    "        if state[0] == 'B':\n",
    "            pre_states = ['B1', 'B2', 'B3', 'Bend']\n",
    "        elif state[0] == 'C':\n",
    "            pre_states = ['C1', 'C2', 'C3', 'Cend']\n",
    "        elif state[0] == 'H':\n",
    "            pre_states = ['H1', 'H2', 'H3', 'Hend']\n",
    "            \n",
    "        if state == 'B1':\n",
    "            pre_states = ['B1', 'B2', 'B3', 'Bend', 'C3', 'H3']\n",
    "        elif state == 'C1':\n",
    "            pre_states = ['C1', 'C2', 'C3', 'Cend', 'B3', 'H3']\n",
    "        elif state == 'H1':\n",
    "            pre_states = ['H1', 'H2', 'H3', 'Hend', 'B3', 'C3']\n",
    "\n",
    "        for pre_state in pre_states:\n",
    "            probability = transition_probs[pre_state][state][0]\\\n",
    "                 * gaussian_prob(evidence_vector[1][0], emission_paras[state][0])\\\n",
    "                 * transition_probs[pre_state][state][1] \\\n",
    "                 * gaussian_prob(evidence_vector[1][1], emission_paras[state][1])\\\n",
    "                 * dict_1[pre_state]\n",
    "            prob_ls[probability] =  pre_state\n",
    "        probability = max(prob_ls)\n",
    "        dict_2[state] = probability\n",
    "        updated_path[state] = path[prob_ls[probability]] + [state]\n",
    "    path = updated_path\n",
    "    \n",
    "\n",
    "    for i in range(len(evidence_vector)):\n",
    "        if i == 0 or i == 1:\n",
    "            continue\n",
    "        updated_path = {}\n",
    "        for state in states:\n",
    "            prob_ls = {}\n",
    "            if state[0] == 'B':\n",
    "                pre_states = ['B1', 'B2', 'B3', 'Bend']\n",
    "            elif state[0] == 'C':\n",
    "                pre_states = ['C1', 'C2', 'C3', 'Cend']\n",
    "            elif state[0] == 'H':\n",
    "                pre_states = ['H1', 'H2', 'H3', 'Hend']\n",
    "            \n",
    "            if state == 'B1':\n",
    "                pre_states = ['B1', 'B2', 'B3', 'Bend', 'C3', 'H3']\n",
    "            elif state == 'C1':\n",
    "                pre_states = ['C1', 'C2', 'C3', 'Cend', 'B3', 'H3']\n",
    "            elif state == 'H1':\n",
    "                pre_states = ['H1', 'H2', 'H3', 'Hend', 'B3', 'C3']\n",
    "\n",
    "            for pre_state in pre_states:\n",
    "                probability = transition_probs[pre_state][state][0]\\\n",
    "                     * gaussian_prob(evidence_vector[i][0], emission_paras[state][0])\\\n",
    "                     * transition_probs[pre_state][state][1] \\\n",
    "                     * gaussian_prob(evidence_vector[i][1], emission_paras[state][1])\\\n",
    "                     * dict_2[pre_state]\n",
    "                prob_ls[probability] =  pre_state\n",
    "            probability = max(prob_ls)\n",
    "            dict_1[state] = probability\n",
    "            updated_path[state] = path[prob_ls[probability]] + [state]\n",
    "        path = updated_path\n",
    "        dict_2 = dict_1\n",
    "        dict_1 = {}\n",
    "\n",
    "    probability = 0  \n",
    "    for state in dict_2:\n",
    "        if dict_2[state] > probability:\n",
    "            probability = dict_2[state]\n",
    "            sequence = path[state] \n",
    "\n",
    "    return sequence, probability\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
